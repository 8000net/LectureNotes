{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Generative adversarial networks were first introduced in 2014. These models are comprised of two networks, the generator and the discriminator (or adversary). The generator produces images and the discriminator estimates if each image came from the generator or the training data.\n",
    "\n",
    "This can also be viewed as a forgery detection task where the generator is making forgeries and the discriminator is learning how to detect forgeries. The objective is to have the discriminator detecting forgeries 50% of the time, or choosing randomly if the image is real or forged. As training goes on, the discriminator learns better and better how to deteck fakes, and the generator improves at fooling the discriminator.\n",
    "\n",
    "# History\n",
    "\n",
    "## 2014 -  Generative Adversarial Nets.\n",
    "GANs were first introduced in 2014 by Ian J. Goodfellow and a team of researchers at the University of Montreal. They showed that this two-model system could be used to train models of opposite, but related tasks. In their work, the implemented the generator and the discriminator as simple multi-layer perceptrons.\n",
    "\n",
    "They based the loss function off of a two-player minmax game function where the discriminator is trying to maximize its score (correct forgery detections) and the generator is trying to minimize its score (forgery detections).\n",
    "\n",
    "<img src=\"./images/gan-minmax.png\">\n",
    "\n",
    "Where $G$ is the generator, $D$ is the discriminator, $x$ is the training data, and $z$ is noise. This is quite different from traditional deep learning models where the objective is to minimize some value. With generative adversarial networks, we are instead trying to balance the performance of the two networks without letting one dominate the other. This can make them difficult to train.\n",
    "\n",
    "In order to avoid overfitting the discriminator, model training alternated between adjusting the discriminator and the generator. Specifically, the discriminator would update for $k$ steps before switching and updating the generator for one step.\n",
    "\n",
    "(Generative Adversarial Nets., Goodfellow et al.)\n",
    "\n",
    "\n",
    "# Present\n",
    "\n",
    "\n",
    "## Common Problems\n",
    "\n",
    "\n",
    "### Mode Collapse\n",
    "\n",
    "\n",
    "### Overpowerment\n",
    "\n",
    "\n",
    "# GAN DeepFake Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Generative Adversarial Nets, Ian J. Goodfellow et al., https://arxiv.org/pdf/1406.2661.pdf\n",
    "\n",
    "Intordiction to generative adversarial networks reference notebook, Francois Chollet: https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.5-introduction-to-gans.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLEnv]",
   "language": "python",
   "name": "conda-env-MLEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
