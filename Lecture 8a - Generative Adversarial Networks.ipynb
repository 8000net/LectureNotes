{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Generative adversarial networks were first introduced in 2014. These models are comprised of two networks, the generator and the discriminator (or adversary). The generator produces images and the discriminator estimates if each image came from the generator or the training data.\n",
    "\n",
    "This can also be viewed as a forgery detection task where the generator is making forgeries and the discriminator is learning how to detect forgeries. The objective is to have the discriminator detecting forgeries 50% of the time, or choosing randomly if the image is real or forged. As training goes on, the discriminator learns better and better how to detect fakes, and the generator improves at fooling the discriminator.\n",
    "\n",
    "The data space that the generator is using to generate images is knows as the latent space, which is periodically updated to form images of higher quality.\n",
    "\n",
    "# History\n",
    "\n",
    "## 2014 -  Generative Adversarial Nets.\n",
    "GANs were first introduced in 2014 by Ian J. Goodfellow and a team of researchers at the University of Montreal. They showed that this two-model system could be used to train models of opposite, but related tasks. In their work, the implemented the generator and the discriminator as simple multi-layer perceptrons.\n",
    "\n",
    "They based the loss function off of a two-player minmax game function where the discriminator is trying to maximize its score (correct forgery detections) and the generator is trying to minimize its score (forgery detections).\n",
    "\n",
    "<img src=\"./images/gan-minmax.png\">\n",
    "\n",
    "Where $G$ is the generator, $D$ is the discriminator, $x$ is the training data, and $z$ is noise. This is quite different from traditional deep learning models where the objective is to minimize some value. With generative adversarial networks, we are instead trying to balance the performance of the two networks without letting one dominate the other. This can make them difficult to train.\n",
    "\n",
    "In order to avoid overfitting the discriminator, model training alternated between adjusting the discriminator and the generator. Specifically, the discriminator would update for $k$ steps before switching and updating the generator for one step.\n",
    "\n",
    "(Generative Adversarial Nets., Goodfellow et al.)\n",
    "\n",
    "## 2015 - Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\n",
    "Deep Convolutional Generative Adversarial Networks (DCGANs) are introduced by a team of researchers at indico Research in Boston. They seek to apply CNNs to unsupervised learning using the two-network generator/descriminator approach put forth by Goodfellow et al. Up until this point, CNNs had primarily been used for supervised learning for classification of images.\n",
    "\n",
    "Radford et al. had two major goals with this research. First, they wanted to train GANs to learn feature representations of unlabeled image and video data so that the representations could be transfered into a separate model that is trained in a supervised manor. Doing this would hopefully speed up the training time of the image classification network because the filters would already be learnt. Second, the team wanted to visualize what filters the GANs learn and how the generator uses those filters to draw new images.\n",
    "\n",
    "The team used three image sets to evaluate their architecture: Large-scale Scene Understanding (LSUN), Imagenet-1k, and a data set of faces. When training on scenes, the generator was able to produce the following images of fake bedrooms.\n",
    "\n",
    "<img src=\"./images/gan-bedrooms.png\">\n",
    "\n",
    "When training on face images, the team was able to perform vector arithmetic on sets of images to create classes of images that were not represented in the original data. For example, by starting with a man with glasses and subtracting a general man and adding a general woman will produce images of a woman with glasses.\n",
    "\n",
    "<img src=\"./images/gan-vector-faces.png\">\n",
    "\n",
    "(Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, Radford et al.)\n",
    "\n",
    "## 2018 - Progressive Growing of GANs for Improved Quality, Stability, and Variation\n",
    "A problem with generating high-resolution images using GANs is that it becomes easier for the descriminator to detect fake images because of the work associated with generating photo-realistic images at a large scale. To address this, team of researchers at NVIDIA introduced a method of generating progressively higher resolution images with GANs by adding new layers to images over many iterations. The training starts with low-resolution images and progressively adds more and more layers that increase the resolution. This allows for a faster training cycle because less time and memory is needed to generate each batch of images.\n",
    "\n",
    "They applied this method to images of celebrities to generate dozens of images of fake celebrities that are photo-realistic. The generator and descriminator are mirror models of each other and layers are added to them at the same time.\n",
    "\n",
    "<img src=\"./images/gan-faces.png\">\n",
    "\n",
    "(Progressive Growing of GANs for Improved Quality, Stability, and Variation, Karras et al.)\n",
    "\n",
    "# Present\n",
    "GANs are promising for various other tasks such as speech synthesis, ...\n",
    "\n",
    "## Common Problems\n",
    "\n",
    "\n",
    "### Mode Collapse\n",
    "\n",
    "\n",
    "### Overpowerment\n",
    "\n",
    "\n",
    "# GAN DeepFake Detection\n",
    "\n",
    "Recent controversial work has been used to transfer the face of one subject to another. One particular implementation made its rounds on the internet as a way of taking a celebrity's face and putting it on content images or video frames.\n",
    "\n",
    "These models show how machine learning is being used for nefarious applications. It would therefore be useful to have a model that is capable of determining whether an image of a celebrity is genuine or has been generated by a faceswap model.\n",
    "\n",
    "GANs are an obvious candidate for this task because of their uses for forgery detection. The generator would forge faceswap images and the descriminator would learn how to detect if the picture is a real photo of someone or if it has been faceswapped.\n",
    "\n",
    "## CNN Detection\n",
    "To examine the performance of GAN faceswap detection, a simple CNN classifer is used to classify the real and fake images. The input data is a set of 4,000 real images and 10,000 images that have already had the face swapped. The swapped images have been swapped to new people and back to the original person. Additionally, some of the real images have been scaled down a random percentage to simulate someone moving further away from the web cam.\n",
    "\n",
    "When trained on real and a variety of fake images, the CNN is able to detect fake images with ~70% accuracy.\n",
    "\n",
    "## GAN Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Generative Adversarial Nets, Ian J. Goodfellow et al., https://arxiv.org/pdf/1406.2661.pdf\n",
    "\n",
    "Introduction to generative adversarial networks reference notebook, Francois Chollet: https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.5-introduction-to-gans.ipynb\n",
    "\n",
    "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, Alec Radford et al.: https://arxiv.org/pdf/1511.06434.pdf\n",
    "\n",
    "Progressive Growing of GANs for Improved Quality, Stability, and Variation, Tero Karras et al.: http://research.nvidia.com/sites/default/files/pubs/2017-10_Progressive-Growing-of/karras2018iclr-paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLEnv]",
   "language": "python",
   "name": "conda-env-MLEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
